/**
 * æ•°æ®æŸ¥è¯¢ä¼˜åŒ–å™¨
 * å®ç°æŸ¥è¯¢ä¼˜åŒ–ã€ç´¢å¼•å»ºè®®ã€æ€§èƒ½ç›‘æ§
 */

import { queryCacheService } from './QueryCacheService.js'

export class QueryOptimizer {
  constructor() {
    // æŸ¥è¯¢æ€§èƒ½ç»Ÿè®¡
    this.performanceStats = new Map()
    
    // æŸ¥è¯¢æ¨¡å¼åˆ†æ
    this.queryPatterns = new Map()
    
    // ä¼˜åŒ–å»ºè®®
    this.optimizationSuggestions = []
    
    // é…ç½®
    this.config = {
      slowQueryThreshold: 1000, // æ…¢æŸ¥è¯¢é˜ˆå€¼ï¼ˆæ¯«ç§’ï¼‰
      patternAnalysisWindow: 100, // æ¨¡å¼åˆ†æçª—å£å¤§å°
      optimizationInterval: 30 * 60 * 1000 // ä¼˜åŒ–åˆ†æé—´éš”ï¼ˆ30åˆ†é’Ÿï¼‰
    }
    
    // å¯åŠ¨æ€§èƒ½ç›‘æ§
    this.startPerformanceMonitoring()
  }

  /**
   * ä¼˜åŒ–æŸ¥è¯¢æ‰§è¡Œ
   * @param {string} queryType - æŸ¥è¯¢ç±»å‹
   * @param {Object} params - æŸ¥è¯¢å‚æ•°
   * @param {Function} queryFn - æŸ¥è¯¢å‡½æ•°
   * @param {Object} options - é€‰é¡¹
   * @returns {Promise<any>} æŸ¥è¯¢ç»“æœ
   */
  async optimizedQuery(queryType, params, queryFn, options = {}) {
    const queryId = this.generateQueryId(queryType, params)
    const cacheKey = this.generateCacheKey(queryType, params)
    
    // è®°å½•æŸ¥è¯¢å¼€å§‹
    const startTime = Date.now()
    this.recordQueryPattern(queryType, params)
    
    try {
      // æŸ¥è¯¢ä¼˜åŒ–ç­–ç•¥é€‰æ‹©
      const strategy = this.selectOptimizationStrategy(queryType, params)
      
      let result
      
      switch (strategy) {
        case 'cache_first':
          result = await this.cacheFirstQuery(cacheKey, queryFn, options)
          break
          
        case 'parallel_batch':
          result = await this.parallelBatchQuery(queryType, params, queryFn, options)
          break
          
        case 'incremental':
          result = await this.incrementalQuery(queryType, params, queryFn, options)
          break
          
        case 'direct':
        default:
          result = await queryFn()
          break
      }
      
      // è®°å½•æ€§èƒ½ç»Ÿè®¡
      const duration = Date.now() - startTime
      this.recordPerformance(queryId, duration, 'success')
      
      return result
      
    } catch (error) {
      const duration = Date.now() - startTime
      this.recordPerformance(queryId, duration, 'error')
      throw error
    }
  }

  /**
   * ç¼“å­˜ä¼˜å…ˆæŸ¥è¯¢ç­–ç•¥
   */
  async cacheFirstQuery(cacheKey, queryFn, options) {
    return await queryCacheService.query(cacheKey, queryFn, {
      type: options.cacheType || 'default',
      ttl: options.cacheTTL
    })
  }

  /**
   * å¹¶è¡Œæ‰¹é‡æŸ¥è¯¢ç­–ç•¥
   */
  async parallelBatchQuery(queryType, params, queryFn, options) {
    // æ£€æŸ¥æ˜¯å¦å¯ä»¥æ‹†åˆ†ä¸ºå¹¶è¡ŒæŸ¥è¯¢
    const subQueries = this.splitIntoSubQueries(queryType, params)
    
    if (subQueries.length <= 1) {
      return await queryFn()
    }
    
    console.log(`ğŸ”„ å¹¶è¡Œæ‰§è¡Œ ${subQueries.length} ä¸ªå­æŸ¥è¯¢`)
    
    const promises = subQueries.map(async (subQuery, index) => {
      const subCacheKey = this.generateCacheKey(queryType, subQuery.params)
      return {
        index,
        result: await queryCacheService.query(subCacheKey, subQuery.queryFn, options)
      }
    })
    
    const results = await Promise.all(promises)
    
    // åˆå¹¶ç»“æœ
    return this.mergeSubQueryResults(queryType, results)
  }

  /**
   * å¢é‡æŸ¥è¯¢ç­–ç•¥
   */
  async incrementalQuery(queryType, params, queryFn, options) {
    // æ£€æŸ¥æ˜¯å¦æœ‰åŸºç¡€æ•°æ®ç¼“å­˜
    const baseKey = this.generateBaseKey(queryType, params)
    const baseData = queryCacheService.get(baseKey)
    
    if (baseData) {
      // æ‰§è¡Œå¢é‡æŸ¥è¯¢
      const incrementalParams = this.generateIncrementalParams(params, baseData.lastUpdate)
      const incrementalData = await queryFn(incrementalParams)
      
      // åˆå¹¶æ•°æ®
      const mergedData = this.mergeIncrementalData(baseData.data, incrementalData)
      
      // æ›´æ–°ç¼“å­˜
      queryCacheService.set(baseKey, {
        data: mergedData,
        lastUpdate: Date.now()
      }, options)
      
      return mergedData
    } else {
      // é¦–æ¬¡æŸ¥è¯¢ï¼Œè·å–å…¨é‡æ•°æ®
      const fullData = await queryFn()
      
      queryCacheService.set(baseKey, {
        data: fullData,
        lastUpdate: Date.now()
      }, options)
      
      return fullData
    }
  }

  /**
   * é€‰æ‹©ä¼˜åŒ–ç­–ç•¥
   */
  selectOptimizationStrategy(queryType, params) {
    // åŸºäºæŸ¥è¯¢ç±»å‹å’Œå‚æ•°é€‰æ‹©ç­–ç•¥
    const patterns = this.queryPatterns.get(queryType)
    
    if (!patterns) {
      return 'cache_first' // é»˜è®¤ç­–ç•¥
    }
    
    // é«˜é¢‘æŸ¥è¯¢ä½¿ç”¨ç¼“å­˜ä¼˜å…ˆ
    if (patterns.frequency > 10) {
      return 'cache_first'
    }
    
    // å¤§æ•°æ®é‡æŸ¥è¯¢è€ƒè™‘å¹¶è¡Œå¤„ç†
    if (this.isLargeDataQuery(queryType, params)) {
      return 'parallel_batch'
    }
    
    // æ—¶é—´åºåˆ—æ•°æ®ä½¿ç”¨å¢é‡æŸ¥è¯¢
    if (this.isTimeSeriesQuery(queryType, params)) {
      return 'incremental'
    }
    
    return 'cache_first'
  }

  /**
   * æ‹†åˆ†ä¸ºå­æŸ¥è¯¢
   */
  splitIntoSubQueries(queryType, params) {
    const subQueries = []
    
    // æ ¹æ®æŸ¥è¯¢ç±»å‹è¿›è¡Œæ‹†åˆ†
    switch (queryType) {
      case 'inventory_by_factory':
        if (params.factories && params.factories.length > 1) {
          params.factories.forEach(factory => {
            subQueries.push({
              params: { ...params, factories: [factory] },
              queryFn: () => this.queryInventoryByFactory({ ...params, factories: [factory] })
            })
          })
        }
        break
        
      case 'quality_analysis':
        if (params.dateRange && this.isLargeDateRange(params.dateRange)) {
          const dateChunks = this.splitDateRange(params.dateRange)
          dateChunks.forEach(chunk => {
            subQueries.push({
              params: { ...params, dateRange: chunk },
              queryFn: () => this.queryQualityAnalysis({ ...params, dateRange: chunk })
            })
          })
        }
        break
    }
    
    return subQueries.length > 0 ? subQueries : [{ params, queryFn: () => {} }]
  }

  /**
   * åˆå¹¶å­æŸ¥è¯¢ç»“æœ
   */
  mergeSubQueryResults(queryType, results) {
    // æŒ‰ç´¢å¼•æ’åº
    results.sort((a, b) => a.index - b.index)
    
    switch (queryType) {
      case 'inventory_by_factory':
        return results.reduce((merged, { result }) => {
          return merged.concat(result || [])
        }, [])
        
      case 'quality_analysis':
        return results.reduce((merged, { result }) => {
          if (!result) return merged
          
          return {
            totalRecords: (merged.totalRecords || 0) + (result.totalRecords || 0),
            passRate: this.calculateAveragePassRate(merged, result),
            defectTypes: this.mergeDefectTypes(merged.defectTypes, result.defectTypes),
            trends: this.mergeTrends(merged.trends, result.trends)
          }
        }, {})
        
      default:
        return results.map(r => r.result)
    }
  }

  /**
   * è®°å½•æŸ¥è¯¢æ¨¡å¼
   */
  recordQueryPattern(queryType, params) {
    const pattern = this.queryPatterns.get(queryType) || {
      frequency: 0,
      lastParams: [],
      avgResponseTime: 0,
      paramPatterns: new Map()
    }
    
    pattern.frequency++
    pattern.lastParams.push(params)
    
    // ä¿æŒæœ€è¿‘çš„å‚æ•°è®°å½•
    if (pattern.lastParams.length > this.config.patternAnalysisWindow) {
      pattern.lastParams.shift()
    }
    
    // åˆ†æå‚æ•°æ¨¡å¼
    this.analyzeParamPatterns(pattern, params)
    
    this.queryPatterns.set(queryType, pattern)
  }

  /**
   * è®°å½•æ€§èƒ½ç»Ÿè®¡
   */
  recordPerformance(queryId, duration, status) {
    const stats = this.performanceStats.get(queryId) || {
      count: 0,
      totalTime: 0,
      avgTime: 0,
      minTime: Infinity,
      maxTime: 0,
      successCount: 0,
      errorCount: 0
    }
    
    stats.count++
    stats.totalTime += duration
    stats.avgTime = stats.totalTime / stats.count
    stats.minTime = Math.min(stats.minTime, duration)
    stats.maxTime = Math.max(stats.maxTime, duration)
    
    if (status === 'success') {
      stats.successCount++
    } else {
      stats.errorCount++
    }
    
    this.performanceStats.set(queryId, stats)
    
    // æ…¢æŸ¥è¯¢è­¦å‘Š
    if (duration > this.config.slowQueryThreshold) {
      console.warn(`ğŸŒ æ…¢æŸ¥è¯¢æ£€æµ‹: ${queryId} - ${duration}ms`)
      this.generateOptimizationSuggestion(queryId, duration)
    }
  }

  /**
   * ç”Ÿæˆä¼˜åŒ–å»ºè®®
   */
  generateOptimizationSuggestion(queryId, duration) {
    const suggestion = {
      queryId,
      duration,
      timestamp: Date.now(),
      type: 'slow_query',
      suggestions: []
    }
    
    // åŸºäºæŸ¥è¯¢IDåˆ†æå»ºè®®
    if (queryId.includes('inventory')) {
      suggestion.suggestions.push('è€ƒè™‘æ·»åŠ å·¥å‚å’Œç‰©æ–™çš„å¤åˆç´¢å¼•')
      suggestion.suggestions.push('ä½¿ç”¨åˆ†é¡µæŸ¥è¯¢å‡å°‘æ•°æ®ä¼ è¾“é‡')
    }
    
    if (queryId.includes('quality')) {
      suggestion.suggestions.push('è€ƒè™‘æŒ‰æ—¶é—´èŒƒå›´é¢„èšåˆè´¨é‡æ•°æ®')
      suggestion.suggestions.push('ä½¿ç”¨ç¼“å­˜å­˜å‚¨å¸¸ç”¨çš„è´¨é‡ç»Ÿè®¡ç»“æœ')
    }
    
    if (duration > 5000) {
      suggestion.suggestions.push('è€ƒè™‘å°†æŸ¥è¯¢æ‹†åˆ†ä¸ºå¤šä¸ªå¹¶è¡Œå­æŸ¥è¯¢')
      suggestion.suggestions.push('æ£€æŸ¥æ•°æ®åº“è¿æ¥æ± é…ç½®')
    }
    
    this.optimizationSuggestions.push(suggestion)
    
    // ä¿æŒæœ€è¿‘çš„å»ºè®®è®°å½•
    if (this.optimizationSuggestions.length > 100) {
      this.optimizationSuggestions.shift()
    }
  }

  /**
   * å¯åŠ¨æ€§èƒ½ç›‘æ§
   */
  startPerformanceMonitoring() {
    setInterval(() => {
      this.analyzePerformanceTrends()
      this.generatePerformanceReport()
    }, this.config.optimizationInterval)
  }

  /**
   * åˆ†ææ€§èƒ½è¶‹åŠ¿
   */
  analyzePerformanceTrends() {
    console.log('ğŸ“Š åˆ†ææŸ¥è¯¢æ€§èƒ½è¶‹åŠ¿...')
    
    for (const [queryId, stats] of this.performanceStats.entries()) {
      if (stats.count > 10 && stats.avgTime > this.config.slowQueryThreshold) {
        console.warn(`âš ï¸ æŒç»­æ…¢æŸ¥è¯¢: ${queryId} - å¹³å‡${stats.avgTime}ms`)
      }
    }
  }

  /**
   * ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
   */
  generatePerformanceReport() {
    const report = {
      timestamp: new Date().toISOString(),
      totalQueries: Array.from(this.performanceStats.values()).reduce((sum, stats) => sum + stats.count, 0),
      avgResponseTime: this.calculateOverallAvgTime(),
      slowQueries: this.getSlowQueries(),
      cacheStats: queryCacheService.getStats(),
      optimizationSuggestions: this.optimizationSuggestions.slice(-10)
    }
    
    console.log('ğŸ“ˆ æŸ¥è¯¢æ€§èƒ½æŠ¥å‘Š:', report)
    return report
  }

  /**
   * è¾…åŠ©æ–¹æ³•
   */
  generateQueryId(queryType, params) {
    const paramStr = Object.keys(params).sort().map(key => `${key}:${params[key]}`).join('|')
    return `${queryType}:${paramStr}`
  }

  generateCacheKey(queryType, params) {
    return queryCacheService.constructor.generateKey(queryType, params)
  }

  generateBaseKey(queryType, params) {
    const baseParams = { ...params }
    delete baseParams.dateRange
    delete baseParams.limit
    delete baseParams.offset
    return this.generateCacheKey(`${queryType}_base`, baseParams)
  }

  isLargeDataQuery(queryType, params) {
    return queryType.includes('report') || 
           (params.limit && params.limit > 1000) ||
           (params.dateRange && this.isLargeDateRange(params.dateRange))
  }

  isTimeSeriesQuery(queryType, params) {
    return queryType.includes('trend') || 
           queryType.includes('history') ||
           params.dateRange
  }

  isLargeDateRange(dateRange) {
    if (!dateRange || !dateRange.start || !dateRange.end) return false
    const start = new Date(dateRange.start)
    const end = new Date(dateRange.end)
    const diffDays = (end - start) / (1000 * 60 * 60 * 24)
    return diffDays > 30 // è¶…è¿‡30å¤©è®¤ä¸ºæ˜¯å¤§èŒƒå›´
  }

  calculateOverallAvgTime() {
    const allStats = Array.from(this.performanceStats.values())
    if (allStats.length === 0) return 0
    
    const totalTime = allStats.reduce((sum, stats) => sum + stats.totalTime, 0)
    const totalCount = allStats.reduce((sum, stats) => sum + stats.count, 0)
    
    return totalCount > 0 ? totalTime / totalCount : 0
  }

  getSlowQueries() {
    return Array.from(this.performanceStats.entries())
      .filter(([, stats]) => stats.avgTime > this.config.slowQueryThreshold)
      .map(([queryId, stats]) => ({ queryId, avgTime: stats.avgTime, count: stats.count }))
      .sort((a, b) => b.avgTime - a.avgTime)
      .slice(0, 10)
  }
}

// åˆ›å»ºå…¨å±€å®ä¾‹
export const queryOptimizer = new QueryOptimizer()
export default queryOptimizer
